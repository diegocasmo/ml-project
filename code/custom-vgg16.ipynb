{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple VGG16\n",
    "\n",
    "Check the devices available. Note you need to have the right version (as in CPU vs GPU version) of TensorFlow installed to harnes the GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Data Splitting\n",
    "<p style='color: red; font-weight: bold;'>Remember to the paths of the directory and that the directory has files!</p>\n",
    "\n",
    "Specify the training sizes here. If `train_split` is <= 1 the training and validation datasets will be split based on that decimal value. Otherwise, the training dataset will be a _fixed number of samples_ from the whole dataset and the validation dataset will be some fraction of that. e.g: \n",
    "\n",
    "```py\n",
    "# example 1\n",
    "train_split = 10000\n",
    "len(train_paths) # 10000\n",
    "len(valid_paths) # 2000 (assuming valid_split is 0.2)\n",
    "\n",
    "# example 2\n",
    "train_split = 0.80\n",
    "len(train_paths) # 49262, (80%)\n",
    "len(valid_paths) # 12316, (20%)\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 106\n",
    "batch_size = 32    # used much later.\n",
    "train_split = 0.8\n",
    "valid_split = 0.2  # used only if train_split > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning images:    49262\n",
      "Validation images: 12316\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_img_paths(target):\n",
    "    '''\n",
    "    Retrieve the full path of all images in the original training dataset\n",
    "    '''\n",
    "    return glob.glob(target + '/*.jpg')\n",
    "\n",
    "data_dir = r'../data'\n",
    "original_data_dir = data_dir + ('/images_training_rev1_%d' % img_size)\n",
    "all_files = pd.DataFrame(load_img_paths(original_data_dir))\n",
    "\n",
    "all_files = all_files.sample(frac=1, random_state=123) # shuffle with seed 123 for reproducability\n",
    "train_paths = []\n",
    "valid_paths = []\n",
    "\n",
    "if train_split <= 1:\n",
    "    frac = int(all_files.shape[0] * train_split)\n",
    "    train_paths = all_files[:frac][0].values.tolist()\n",
    "    valid_paths = all_files[frac:][0].values.tolist()\n",
    "else:\n",
    "    valid_frac = int(train_split * valid_split)\n",
    "    train_paths = all_files[:train_split][0].values.tolist()\n",
    "    valid_paths = all_files[train_split:train_split+valid_frac][0].values.tolist()\n",
    "\n",
    "assert(len(train_paths) > 0)\n",
    "print('Traning images:    %d' % len(train_paths))\n",
    "print('Validation images: %d' % len(valid_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100008</td>\n",
       "      <td>0.383147</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.578401</td>\n",
       "      <td>0.418398</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100023</td>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.467370</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.459950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100053</td>\n",
       "      <td>0.765717</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100078</td>\n",
       "      <td>0.693377</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.068059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.129071</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.049466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100090</td>\n",
       "      <td>0.933839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100008  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452   \n",
       "1    100023  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370   \n",
       "2    100053  0.765717  0.177352  0.056931  0.000000  0.177352  0.000000   \n",
       "3    100078  0.693377  0.238564  0.068059  0.000000  0.238564  0.109493   \n",
       "4    100090  0.933839  0.000000  0.066161  0.000000  0.000000  0.000000   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.578401  0.418398  0.198455    ...      0.000000   0.279952   0.138445   \n",
       "1  0.165229  0.591328  0.041271    ...      0.018764   0.000000   0.131378   \n",
       "2  0.177352  0.000000  0.177352    ...      0.000000   0.000000   0.000000   \n",
       "3  0.129071  0.189098  0.049466    ...      0.000000   0.094549   0.000000   \n",
       "4  0.000000  0.000000  0.000000    ...      0.000000   0.000000   0.000000   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.000000   0.000000   0.092886        0.0        0.0        0.0   0.325512  \n",
       "1   0.459950   0.000000   0.591328        0.0        0.0        0.0   0.000000  \n",
       "2   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "3   0.094549   0.189098   0.000000        0.0        0.0        0.0   0.000000  \n",
       "4   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_dir + '/training_solutions_rev1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_map = {}\n",
    "for ind, row in df.iterrows():\n",
    "    _id = int(row['GalaxyID'])\n",
    "    y_map[_id] = row[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model\n",
    "The path cells above are necessary to run before building the model, as we automatically pass the input shape to the model builder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\TWright\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15944193096998881410\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3196952576\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 12526261207021251731\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x18386ef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "def ConvBlock(layers, model, num_filters):\n",
    "    \"\"\"\n",
    "    Create a layered Conv/Pooling block\n",
    "    \"\"\"\n",
    "    for i in range(layers):\n",
    "        model.add(Conv2D(num_filters, (3, 3), activation='relu', padding='same')) # 3x3 filter size \n",
    "        \n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2), data_format='channels_first'))\n",
    "\n",
    "def FCBlock(model, size=4096):\n",
    "    \"\"\"\n",
    "    Fully connected block with ReLU and dropout\n",
    "    \"\"\"\n",
    "    model.add(Dense(size, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "def my_VGG16(input_shape):\n",
    "    \"\"\"\n",
    "    Implement VGG16 architecture\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Lambda(lambda x : x, input_shape=input_shape))\n",
    "    \n",
    "    ConvBlock(2, model, 64)\n",
    "    ConvBlock(2, model, 128)\n",
    "    ConvBlock(3, model, 256)\n",
    "    ConvBlock(3, model, 512)\n",
    "    ConvBlock(3, model, 512)\n",
    "\n",
    "    model.add(Flatten())\n",
    "    FCBlock(model)\n",
    "    FCBlock(model)\n",
    "\n",
    "    model.add(Dense(37, activation = 'sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 3, 106, 106)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 3, 106, 64)        61120     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 106, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 3, 53, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 53, 128)        36992     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 3, 53, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 3, 26, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 3, 26, 256)        147712    \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 3, 26, 256)        590080    \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 3, 26, 256)        590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 13, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 3, 13, 512)        590336    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 3, 13, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 3, 13, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 3, 6, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              9441280   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 37)                151589    \n",
      "=================================================================\n",
      "Total params: 39,194,405\n",
      "Trainable params: 39,194,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "from skimage.io import imread\n",
    "\n",
    "im_shape = imread(train_paths[0]).T.shape\n",
    "\n",
    "# Then create the corresponding model \n",
    "my_model = my_VGG16(im_shape)\n",
    "optimizer = RMSprop(lr=1e-6)\n",
    "my_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp directory already exists\n"
     ]
    }
   ],
   "source": [
    "from os import path\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.preprocessing.image import img_to_array\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "# Will output sequence of tuples (image, test) given a datapath\n",
    "def fetch_images(paths, batch_size=32):\n",
    "    while 1: # while 1 makes it loop around when outerloop finishes\n",
    "        for i in range(0,len(paths),batch_size):\n",
    "            X = np.zeros(shape=(batch_size, im_shape[0], im_shape[1], im_shape[2]))\n",
    "            y = np.zeros(shape=(batch_size, 37))\n",
    "            for j in range(batch_size):\n",
    "                ind = (i+j) % len(paths)\n",
    "                fname = paths[ind]\n",
    "                # load image from preprocessed images, much faster this way.\n",
    "                image = imread(fname).T\n",
    "                X[j] = img_to_array(image)\n",
    "                file_id = path.split(fname)[-1] \\\n",
    "                              .split('.')[0]\n",
    "                file_id = int(file_id)\n",
    "                y[j] = y_map[file_id]\n",
    "            yield (X, y)\n",
    "        \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')\n",
    "\n",
    "# create weights file if it doesn't exist for ModelCheckpoint\n",
    "from os import mkdir\n",
    "try: \n",
    "    mkdir('tmp')\n",
    "except FileExistsError:\n",
    "    print('tmp directory already exists')\n",
    "    \n",
    "# descriptive weight file naming\n",
    "checkpointer = ModelCheckpoint(filepath=('tmp/weights-%db-%d-%d-%d_hsv.hdf5' % \n",
    "                                         (batch_size, img_size, train_split*100, (1-train_split)*100)), \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "# history function\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning images:    49262\n",
      "Validation images: 12316\n",
      "Training steps:    1539\n",
      "Validation steps:  384\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch  = int(len(train_paths) / batch_size)\n",
    "validation_steps = int(len(valid_paths) / batch_size)\n",
    "\n",
    "print('Traning images:    %d' % len(train_paths))\n",
    "print('Validation images: %d' % len(valid_paths))\n",
    "print('Training steps:    %d' % steps_per_epoch)\n",
    "print('Validation steps:  %d' % validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 1081s - loss: 0.0606 - val_loss: 0.0269\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02692, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 2/50\n",
      " - 163s - loss: 0.0289 - val_loss: 0.0266\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.02692 to 0.02656, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 3/50\n",
      " - 164s - loss: 0.0279 - val_loss: 0.0259\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.02656 to 0.02590, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 4/50\n",
      " - 164s - loss: 0.0262 - val_loss: 0.0236\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02590 to 0.02355, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 5/50\n",
      " - 160s - loss: 0.0245 - val_loss: 0.0230\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02355 to 0.02297, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 6/50\n",
      " - 156s - loss: 0.0239 - val_loss: 0.0226\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02297 to 0.02263, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 7/50\n",
      " - 156s - loss: 0.0235 - val_loss: 0.0224\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02263 to 0.02238, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 8/50\n",
      " - 155s - loss: 0.0231 - val_loss: 0.0221\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02238 to 0.02211, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 9/50\n",
      " - 156s - loss: 0.0228 - val_loss: 0.0219\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02211 to 0.02191, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 10/50\n",
      " - 156s - loss: 0.0226 - val_loss: 0.0217\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02191 to 0.02170, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 11/50\n",
      " - 156s - loss: 0.0223 - val_loss: 0.0215\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.02170 to 0.02154, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 12/50\n",
      " - 155s - loss: 0.0222 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.02154 to 0.02140, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 13/50\n",
      " - 155s - loss: 0.0220 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.02140 to 0.02135, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 14/50\n",
      " - 155s - loss: 0.0219 - val_loss: 0.0213\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02135 to 0.02127, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 15/50\n",
      " - 155s - loss: 0.0217 - val_loss: 0.0212\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.02127 to 0.02122, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 16/50\n",
      " - 156s - loss: 0.0216 - val_loss: 0.0210\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.02122 to 0.02105, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 17/50\n",
      " - 156s - loss: 0.0215 - val_loss: 0.0211\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.02105\n",
      "Epoch 18/50\n",
      " - 155s - loss: 0.0214 - val_loss: 0.0209\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.02105 to 0.02089, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 19/50\n",
      " - 156s - loss: 0.0213 - val_loss: 0.0208\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02089 to 0.02077, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 20/50\n",
      " - 156s - loss: 0.0212 - val_loss: 0.0207\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02077 to 0.02069, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 21/50\n",
      " - 156s - loss: 0.0211 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02069 to 0.02063, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 22/50\n",
      " - 155s - loss: 0.0210 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02063\n",
      "Epoch 23/50\n",
      " - 156s - loss: 0.0209 - val_loss: 0.0204\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02063 to 0.02042, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 24/50\n",
      " - 156s - loss: 0.0208 - val_loss: 0.0204\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02042 to 0.02039, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 25/50\n",
      " - 156s - loss: 0.0207 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.02039 to 0.02030, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 26/50\n",
      " - 155s - loss: 0.0206 - val_loss: 0.0202\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.02030 to 0.02020, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 27/50\n",
      " - 155s - loss: 0.0205 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.02020 to 0.02013, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 28/50\n",
      " - 155s - loss: 0.0204 - val_loss: 0.0203\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.02013\n",
      "Epoch 29/50\n",
      " - 155s - loss: 0.0203 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.02013 to 0.02010, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 30/50\n",
      " - 155s - loss: 0.0202 - val_loss: 0.0201\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.02010\n",
      "Epoch 31/50\n",
      " - 155s - loss: 0.0202 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.02010 to 0.01982, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 32/50\n",
      " - 155s - loss: 0.0201 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.01982 to 0.01976, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 33/50\n",
      " - 155s - loss: 0.0200 - val_loss: 0.0197\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.01976 to 0.01974, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 34/50\n",
      " - 155s - loss: 0.0199 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.01974 to 0.01963, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 35/50\n",
      " - 155s - loss: 0.0198 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.01963 to 0.01960, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 36/50\n",
      " - 155s - loss: 0.0198 - val_loss: 0.0196\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01960\n",
      "Epoch 37/50\n",
      " - 155s - loss: 0.0197 - val_loss: 0.0195\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.01960 to 0.01947, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 38/50\n",
      " - 155s - loss: 0.0196 - val_loss: 0.0194\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.01947 to 0.01940, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 39/50\n",
      " - 157s - loss: 0.0196 - val_loss: 0.0193\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.01940 to 0.01933, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 40/50\n",
      " - 156s - loss: 0.0195 - val_loss: 0.0193\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.01933 to 0.01927, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 41/50\n",
      " - 156s - loss: 0.0195 - val_loss: 0.0192\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.01927 to 0.01921, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 42/50\n",
      " - 155s - loss: 0.0194 - val_loss: 0.0192\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.01921 to 0.01920, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 43/50\n",
      " - 156s - loss: 0.0193 - val_loss: 0.0193\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.01920\n",
      "Epoch 44/50\n",
      " - 156s - loss: 0.0193 - val_loss: 0.0191\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.01920 to 0.01907, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 45/50\n",
      " - 155s - loss: 0.0192 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.01907 to 0.01903, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 46/50\n",
      " - 156s - loss: 0.0191 - val_loss: 0.0190\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.01903 to 0.01899, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 47/50\n",
      " - 156s - loss: 0.0191 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.01899 to 0.01892, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 48/50\n",
      " - 155s - loss: 0.0190 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.01892 to 0.01889, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 49/50\n",
      " - 156s - loss: 0.0190 - val_loss: 0.0188\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.01889 to 0.01883, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n",
      "Epoch 50/50\n",
      " - 156s - loss: 0.0189 - val_loss: 0.0188\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.01883 to 0.01880, saving model to tmp/weights-32b-106-80-19_hsv.hdf5\n"
     ]
    }
   ],
   "source": [
    "hist = my_model.fit_generator(fetch_images(train_paths, batch_size),\n",
    "    steps_per_epoch=steps_per_epoch, \n",
    "    epochs=50,\n",
    "    validation_data=fetch_images(valid_paths, batch_size),\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=2,\n",
    "    workers=2,\n",
    "    callbacks=[history,checkpointer,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35798457, 0.6290228 , 0.0200269 , ..., 0.01086278, 0.00995334,\n",
       "        0.08564453],\n",
       "       [0.20595817, 0.7826579 , 0.01618458, ..., 0.0334571 , 0.02524652,\n",
       "        0.16165155],\n",
       "       [0.61619556, 0.3516831 , 0.04105635, ..., 0.00115868, 0.00156241,\n",
       "        0.02738768],\n",
       "       ...,\n",
       "       [0.68675387, 0.27478898, 0.05912217, ..., 0.00391908, 0.00447792,\n",
       "        0.05577543],\n",
       "       [0.19317822, 0.7917809 , 0.01400835, ..., 0.03043245, 0.02229139,\n",
       "        0.16329081],\n",
       "       [0.3879092 , 0.58302426, 0.03251314, ..., 0.01132549, 0.0110871 ,\n",
       "        0.08761862]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = my_model.predict_generator(fetch_images(train_paths, batch_size), steps=5)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.epoch,hist.history['loss'],    label='Test')\n",
    "plt.plot(hist.epoch,hist.history['val_loss'],label='Validation',linestyle='--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate submission\n",
    "There is another dedicated file for this which is specifically for testing out weight.hdf5 files. Run this so you don't have to shut down this kernel and load the weights only to find you've run out of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imreaad' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-dbb6410a3f3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m predictions = my_model.predict_generator(fetch_test_images(),\n\u001b[0;32m     25\u001b[0m                         \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                         max_queue_size=32,)\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   1390\u001b[0m                                             \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m                                             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m                                             verbose=verbose)\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[1;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[0;32m   2520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2521\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2522\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2523\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2524\u001b[0m                     \u001b[1;31m# Compatibility with the generators\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m                 \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36m_data_generator_task\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    656\u001b[0m                             \u001b[1;31m# => Serialize calls to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m                             \u001b[1;31m# infinite iterator/generator's next() function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m                             \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-dbb6410a3f3a>\u001b[0m in \u001b[0;36mfetch_test_images\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimreaad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imreaad' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "\n",
    "def fetch_test_images():\n",
    "    while 1:\n",
    "        for fname in test_files:\n",
    "            image = imread(fname).T\n",
    "            image = img_to_array(image)\n",
    "            test = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "            yield (test)\n",
    "            \n",
    "test_files = glob.glob(('../data/images_test_rev1_%d/*.jpg' % img_size))\n",
    "\n",
    "predictions = my_model.predict_generator(fetch_test_images(),\n",
    "                        steps=len(test_files),\n",
    "                        max_queue_size=32,)\n",
    "\n",
    "from os import path\n",
    "\n",
    "header = open('../data/all_zeros_benchmark.csv','r').readlines()[0]\n",
    "\n",
    "with open('submission_1.csv','w') as outfile:\n",
    "    outfile.write(header)\n",
    "    for i, fname in enumerate(test_files):\n",
    "        fname = test_files[i]\n",
    "        file_id = path.split(fname)[-1] \\\n",
    "                      .split('.')[0]\n",
    "        pred = predictions[i]\n",
    "        outline = file_id + \",\" + \",\".join([str(x) for x in pred])\n",
    "        outfile.write(outline + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
