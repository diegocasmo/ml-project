{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Galaxy Zoo - The Galaxy Challenge](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: Images provided by Kaggle must be unpacked in a folder called ``./data/images_training_rev1`` (at the root of the project)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll proceed to create an 80/20 split of the dataset. To do this, we'll randomly select 80% of the images and place them in a directory. These images will be all potentially used for training later on. The remaining 20% of the images will be placed in a different directory and these will be used to validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Save data directory locations\n",
    "data_dir = r'../data'\n",
    "original_data_dir = data_dir + '/images_training_rev1'\n",
    "training_dir = data_dir + '/training'\n",
    "validation_dir = data_dir + '/validation'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "def load_img_paths():\n",
    "    '''\n",
    "    Retrieve the full path of all images in the dataset\n",
    "    '''\n",
    "    return glob.glob(original_data_dir + '/*.jpg')\n",
    "\n",
    "def create_temp_datasets(img_paths, train_size = 4, validation_size = 2, test_size = 4):\n",
    "    '''\n",
    "    Randomly select images to be in the training, validation, and test datasets\n",
    "    '''\n",
    "    assert(len(img_paths) > 0)\n",
    "    assert(train_size > 0)\n",
    "    assert(validation_size > 0)\n",
    "    assert(test_size > 0)\n",
    "    assert(len(img_paths) >= (train_size + validation_size + test_size))\n",
    "\n",
    "    # Randomly select images that will be in each set\n",
    "    random.shuffle(img_paths)\n",
    "    train_img_paths = img_paths[0:train_size]\n",
    "    validation_img_paths = img_paths[train_size: (train_size + validation_size)]\n",
    "    test_img_paths = img_paths[(train_size + validation_size): (train_size + validation_size + test_size)]\n",
    "    \n",
    "    # Create training, validation, and test directories \n",
    "    if not os.path.exists(training_dir):\n",
    "        os.makedirs(training_dir)\n",
    "    if not os.path.exists(validation_dir):\n",
    "        os.makedirs(validation_dir)\n",
    "    if not os.path.exists(test_dir):\n",
    "        os.makedirs(test_dir)\n",
    "        \n",
    "    # Place training, validation, and test images in their respective directories\n",
    "    for x in train_img_paths:\n",
    "        shutil.copyfile(x, x.replace(original_data_dir, training_dir))\n",
    "    for x in validation_img_paths:\n",
    "        shutil.copyfile(x, x.replace(original_data_dir, validation_dir))\n",
    "    for x in test_img_paths:\n",
    "        shutil.copyfile(x, x.replace(original_data_dir, test_dir))\n",
    "        \n",
    "def remove_temp_datasets():\n",
    "    '''\n",
    "    Remove directories that were temporary created to save the training, validation, and test\n",
    "    '''\n",
    "    shutil.rmtree(training_dir)\n",
    "    shutil.rmtree(validation_dir)\n",
    "    shutil.rmtree(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and execute the helper methods defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the size of each of the datasets we'll be dealing with\n",
    "train_size = 4000\n",
    "validation_size = 500\n",
    "test_size = 4000\n",
    "\n",
    "img_paths = load_img_paths()\n",
    "if len(img_paths) > 0:\n",
    "    create_temp_datasets(img_paths, train_size, validation_size, test_size)\n",
    "else:\n",
    "    msg = \"\"\"\n",
    "        No images were found in the '%s' directory. Either training, validation and test\n",
    "        directories have already been created, or the datasets structure is not correctly setup.\n",
    "    \"\"\" % original_data_dir\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
