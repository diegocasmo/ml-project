\section{The Dataset}

The "Galaxy Zoo" dataset consists of a total \numprint{141,553} images. These are further down split into \numprint{61578} images for training, each with their respective probability distributions for the classifications for each of the inputs, and finally \numprint{79975} images for testing.

As a crowd-sourced volunteer effort, images of the dataset were classified across 37 different categories. Each of the 37 categories has a floating point number between $0$ and $1$ inclusive. These numbers represent a shape of a galaxy in 37 different categories as identified by the volunteers. These shapes are related to probabilities for each category; a number close to 1 indicates many users identified this category for the galaxy image with a high level of confidence, while numbers close to $0$ indicate otherwise.

Hence, rather than a classification problem, this is a regression problem. The task is to determine the fraction of people who would classify a galaxy has having a particular shape or not.

\subsection{Data Preprocessing}

In each image, the object of interest is centered. We can exploit this characteristic by sub-sampling the image essentially carving off unnecessary information in each image which could impair our network in.

image down-sampling (non-destructive cropping to reduce the number of parameters feed to the network)

Down sampling helps the CNN learn which regions are related to each specific expression and also enables the CNN to be performed on the GPU more efficiently \cite{deep-learning-review}.

talk about training set partition into training, validation, and tests sets for faster evaluation of the model

How are images loaded (too many to load all of them at once)? We should consider randomly selecting 'x' number of images to train the network using stochastic mini-batch.
