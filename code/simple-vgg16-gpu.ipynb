{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple VGG16\n",
    "\n",
    "Check the devices available. Note you need to have the right version (as in CPU vs GPU version) of TensorFlow installed to harnes the GPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5014224927300424084\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3388993536\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 6862793787230359388\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 970, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.Session at 0x129f3f28>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allocator_type = 'BFC'\n",
    "tf.Session(config = config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can take a bit of time if it's the first time you're running it. It will download a Keras model equivalent to VGG-16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.applications import vgg16\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "#Load the VGG model\n",
    "vgg_model = vgg16.VGG16(weights='imagenet', input_shape=(212,212,3), include_top=False, pooling='max')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "Changing the last layer from 1000 prediction to 37 predictions\n",
    "my_model is the vgg model if you want to use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 212, 212, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 212, 212, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 212, 212, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 106, 106, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 106, 106, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 106, 106, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 53, 53, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 53, 53, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 53, 53, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 53, 53, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 26, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 26, 26, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 26, 26, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 26, 26, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 13, 13, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 13, 13, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d_1 (Glob (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "predictions_m (Dense)        (None, 37)                18981     \n",
      "=================================================================\n",
      "Total params: 14,733,669\n",
      "Trainable params: 14,733,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "#Add a layer where input is the output of the  second last layer \n",
    "x = Dense(37, activation='sigmoid', name='predictions_m')(vgg_model.layers[-1].output)\n",
    "\n",
    "#Then create the corresponding model \n",
    "\n",
    "optimizer = RMSprop(lr=1e-6)\n",
    "my_model = Model(inputs=vgg_model.input, outputs=x)\n",
    "my_model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paths\n",
    "Remember to check for the path of the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/training\\\\100023.jpg',\n",
       " '../data/training\\\\100128.jpg',\n",
       " '../data/training\\\\100143.jpg',\n",
       " '../data/training\\\\100237.jpg',\n",
       " '../data/training\\\\100335.jpg']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def load_img_paths(target):\n",
    "    '''\n",
    "    Retrieve the full path of all images in the original training dataset\n",
    "    '''\n",
    "    return glob.glob(target + '/*.jpg')\n",
    "\n",
    "data_dir = r'../data'\n",
    "original_data_dir = data_dir + '/images_training_rev1'\n",
    "training_dir      = data_dir + '/training'\n",
    "validation_dir    = data_dir + '/validation'\n",
    "test_dir          = data_dir + '/test'\n",
    "\n",
    "# Load image file names\n",
    "train_paths = load_img_paths(training_dir)\n",
    "valid_paths = load_img_paths(validation_dir)\n",
    "test_paths = load_img_paths(test_dir)\n",
    "train_paths[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "image = load_img(train_paths[0], target_size=(224, 224))\n",
    "\n",
    "from keras.preprocessing.image import img_to_array\n",
    "# convert the image pixels to a numpy array\n",
    "image = img_to_array(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network expects one or more images as input; that means the input array will need to be 4-dimensional: samples, rows, columns, and channels.\n",
    "\n",
    "We only have one sample (one image). We can reshape the array by calling reshape() and adding the extra dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GalaxyID</th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100008</td>\n",
       "      <td>0.383147</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616853</td>\n",
       "      <td>0.038452</td>\n",
       "      <td>0.578401</td>\n",
       "      <td>0.418398</td>\n",
       "      <td>0.198455</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.279952</td>\n",
       "      <td>0.138445</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.092886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.325512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100023</td>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.467370</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.459950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100053</td>\n",
       "      <td>0.765717</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.056931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100078</td>\n",
       "      <td>0.693377</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.068059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.238564</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.129071</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.049466</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094549</td>\n",
       "      <td>0.189098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100090</td>\n",
       "      <td>0.933839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066161</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   GalaxyID  Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  \\\n",
       "0    100008  0.383147  0.616853  0.000000  0.000000  0.616853  0.038452   \n",
       "1    100023  0.327001  0.663777  0.009222  0.031178  0.632599  0.467370   \n",
       "2    100053  0.765717  0.177352  0.056931  0.000000  0.177352  0.000000   \n",
       "3    100078  0.693377  0.238564  0.068059  0.000000  0.238564  0.109493   \n",
       "4    100090  0.933839  0.000000  0.066161  0.000000  0.000000  0.000000   \n",
       "\n",
       "   Class3.2  Class4.1  Class4.2    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "0  0.578401  0.418398  0.198455    ...      0.000000   0.279952   0.138445   \n",
       "1  0.165229  0.591328  0.041271    ...      0.018764   0.000000   0.131378   \n",
       "2  0.177352  0.000000  0.177352    ...      0.000000   0.000000   0.000000   \n",
       "3  0.129071  0.189098  0.049466    ...      0.000000   0.094549   0.000000   \n",
       "4  0.000000  0.000000  0.000000    ...      0.000000   0.000000   0.000000   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "0   0.000000   0.000000   0.092886        0.0        0.0        0.0   0.325512  \n",
       "1   0.459950   0.000000   0.591328        0.0        0.0        0.0   0.000000  \n",
       "2   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "3   0.094549   0.189098   0.000000        0.0        0.0        0.0   0.000000  \n",
       "4   0.000000   0.000000   0.000000        0.0        0.0        0.0   0.000000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # reshape data for the model\n",
    "# image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "\n",
    "# # prepare the image for the VGG model\n",
    "# image = preprocess_input(image)\n",
    "\n",
    "# # predict the probability across all output classes\n",
    "# output = my_model.predict(image)\n",
    "\n",
    "df = pd.read_csv(data_dir + '/training_solutions_rev1.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting\n",
    "Getting the training data number from the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class1.1</th>\n",
       "      <th>Class1.2</th>\n",
       "      <th>Class1.3</th>\n",
       "      <th>Class2.1</th>\n",
       "      <th>Class2.2</th>\n",
       "      <th>Class3.1</th>\n",
       "      <th>Class3.2</th>\n",
       "      <th>Class4.1</th>\n",
       "      <th>Class4.2</th>\n",
       "      <th>Class5.1</th>\n",
       "      <th>...</th>\n",
       "      <th>Class9.3</th>\n",
       "      <th>Class10.1</th>\n",
       "      <th>Class10.2</th>\n",
       "      <th>Class10.3</th>\n",
       "      <th>Class11.1</th>\n",
       "      <th>Class11.2</th>\n",
       "      <th>Class11.3</th>\n",
       "      <th>Class11.4</th>\n",
       "      <th>Class11.5</th>\n",
       "      <th>Class11.6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.327001</td>\n",
       "      <td>0.663777</td>\n",
       "      <td>0.009222</td>\n",
       "      <td>0.031178</td>\n",
       "      <td>0.632599</td>\n",
       "      <td>0.46737</td>\n",
       "      <td>0.165229</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.041271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131378</td>\n",
       "      <td>0.45995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.591328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class1.1  Class1.2  Class1.3  Class2.1  Class2.2  Class3.1  Class3.2  \\\n",
       "1  0.327001  0.663777  0.009222  0.031178  0.632599   0.46737  0.165229   \n",
       "\n",
       "   Class4.1  Class4.2  Class5.1    ...      Class9.3  Class10.1  Class10.2  \\\n",
       "1  0.591328  0.041271       0.0    ...      0.018764        0.0   0.131378   \n",
       "\n",
       "   Class10.3  Class11.1  Class11.2  Class11.3  Class11.4  Class11.5  Class11.6  \n",
       "1    0.45995        0.0   0.591328        0.0        0.0        0.0        0.0  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import path # removes confusion with / and \\ (windows)\n",
    "file_id = path.split(train_paths[0])[-1] \\\n",
    "              .split('.')[0] # remove file extension\n",
    "fd = int(file_id)\n",
    "\n",
    "row = df.loc[df['GalaxyID'] == fd].loc[:,df.columns != 'GalaxyID']\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "\n",
    "def preprocess_image(fname):\n",
    "    sample_img = imread(train_paths[0])\n",
    "    sample_img = sample_img.T[:,106:106*3,106:106*3]\n",
    "    sample_img = resize(sample_img, (3, 212, 212), mode='reflect')\n",
    "    return sample_img.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp directory already exists\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "\n",
    "# Will output sequence of tuples (image, test) given a datapath\n",
    "def fetch_images(paths):\n",
    "    for fname in paths:\n",
    "        image = preprocess_image(fname)\n",
    "        image = img_to_array(image)\n",
    "        image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
    "        train = preprocess_input(image)\n",
    "        file_id = path.split(fname)[-1] \\\n",
    "                      .split('.')[0]\n",
    "        fd = int(file_id)\n",
    "        test = df.loc[df['GalaxyID'] == fd].loc[:,df.columns != 'GalaxyID']\n",
    "        yield (train, [test])\n",
    "        \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')\n",
    "\n",
    "# create weights file if it doesn't exist for ModelCheckpoint\n",
    "from os import mkdir\n",
    "try: \n",
    "    mkdir('tmp')\n",
    "except FileExistsError:\n",
    "    print('tmp directory already exists')\n",
    "checkpointer = ModelCheckpoint(filepath='tmp/weights.hdf5', verbose=1, save_best_only=True)\n",
    "\n",
    "# history function\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 23s - loss: 0.1778 - val_loss: 0.1031\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10314, saving model to tmp/weights.hdf5\n",
      "Epoch 2/50\n",
      " - 19s - loss: 0.1018 - val_loss: 0.1002\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10314 to 0.10022, saving model to tmp/weights.hdf5\n",
      "Epoch 3/50\n",
      " - 19s - loss: 0.1010 - val_loss: 0.0995\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10022 to 0.09947, saving model to tmp/weights.hdf5\n",
      "Epoch 4/50\n",
      " - 19s - loss: 0.1012 - val_loss: 0.0996\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09947\n",
      "Epoch 5/50\n",
      " - 19s - loss: 0.0894 - val_loss: 0.0811\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09947 to 0.08109, saving model to tmp/weights.hdf5\n",
      "Epoch 6/50\n",
      " - 19s - loss: 0.0780 - val_loss: 0.0826\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08109\n",
      "Epoch 7/50\n",
      " - 20s - loss: 0.0742 - val_loss: 0.0588\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08109 to 0.05878, saving model to tmp/weights.hdf5\n",
      "Epoch 8/50\n",
      " - 19s - loss: 0.0629 - val_loss: 0.0602\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.05878\n",
      "Epoch 9/50\n",
      " - 19s - loss: 0.0611 - val_loss: 0.0584\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.05878 to 0.05839, saving model to tmp/weights.hdf5\n",
      "Epoch 10/50\n",
      " - 19s - loss: 0.0478 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.05839 to 0.03890, saving model to tmp/weights.hdf5\n",
      "Epoch 11/50\n",
      " - 19s - loss: 0.0431 - val_loss: 0.0478\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03890\n",
      "Epoch 12/50\n",
      " - 19s - loss: 0.0454 - val_loss: 0.0460\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.03890\n",
      "Epoch 13/50\n",
      " - 19s - loss: 0.0435 - val_loss: 0.0418\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.03890\n",
      "Epoch 14/50\n",
      " - 19s - loss: 0.0443 - val_loss: 0.0510\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.03890\n",
      "Epoch 15/50\n",
      " - 19s - loss: 0.0433 - val_loss: 0.0418\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.03890\n",
      "Epoch 16/50\n",
      " - 19s - loss: 0.0462 - val_loss: 0.0385\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03890 to 0.03853, saving model to tmp/weights.hdf5\n",
      "Epoch 17/50\n",
      " - 19s - loss: 0.0312 - val_loss: 0.0283\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03853 to 0.02829, saving model to tmp/weights.hdf5\n",
      "Epoch 18/50\n",
      " - 19s - loss: 0.0288 - val_loss: 0.0331\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.02829\n",
      "Epoch 19/50\n",
      " - 19s - loss: 0.0297 - val_loss: 0.0280\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02829 to 0.02803, saving model to tmp/weights.hdf5\n",
      "Epoch 20/50\n",
      " - 19s - loss: 0.0270 - val_loss: 0.0257\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02803 to 0.02567, saving model to tmp/weights.hdf5\n",
      "Epoch 21/50\n",
      " - 19s - loss: 0.0289 - val_loss: 0.0278\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02567\n",
      "Epoch 22/50\n",
      " - 19s - loss: 0.0291 - val_loss: 0.0339\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02567\n",
      "Epoch 23/50\n",
      " - 19s - loss: 0.0278 - val_loss: 0.0306\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.02567\n",
      "Epoch 24/50\n",
      " - 19s - loss: 0.0275 - val_loss: 0.0280\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.02567\n",
      "Epoch 25/50\n",
      " - 19s - loss: 0.0289 - val_loss: 0.0303\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.02567\n",
      "Epoch 26/50\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "steps_per_epoch  = len(train_paths) / batch_size\n",
    "validation_steps = len(valid_paths) / batch_size\n",
    "hist = my_model.fit_generator(fetch_images(train_paths),\n",
    "    steps_per_epoch=steps_per_epoch, \n",
    "    epochs=50,\n",
    "    validation_data=fetch_images(valid_paths),\n",
    "    validation_steps=validation_steps,\n",
    "    verbose=2,\n",
    "    callbacks=[history,checkpointer,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(hist.epoch,hist.history['loss'],    label='Test')\n",
    "plt.plot(hist.epoch,hist.history['val_loss'],label='Validation',linestyle='--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_paths)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_paths)/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
