{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Galaxy Zoo - The Galaxy Challenge](https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important note: Images provided by Kaggle must be unpacked in a folder called ``./data/images_training_rev1`` (at the root of the project)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll proceed to create an 80/20 split of the dataset. To do this, we'll randomly select 80% of the images and place them in a directory. These images will be all potentially used for training later on. The remaining 20% of the images will be placed in a different directory and these will be used to validate our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Save data directory in variables\n",
    "data_dir = '../data'\n",
    "original_data_dir = data_dir + '/images_training_rev1'\n",
    "training_dir = data_dir + '/training'\n",
    "validation_dir = data_dir + '/validation'\n",
    "\n",
    "def load_img_paths():\n",
    "    '''\n",
    "    Retrieve the full path of all images in the dataset\n",
    "    '''\n",
    "    return glob.glob(original_data_dir + '/*.jpg')\n",
    "\n",
    "def get_train_set_size(dataset_size, train_set_split = 80):\n",
    "    '''\n",
    "    Return size of training set based on the size of the entire dataset and the desired split\n",
    "    '''\n",
    "    assert(dataset_size > 0)\n",
    "    assert(train_set_split > 0)\n",
    "    assert(train_set_split < 100)\n",
    "    \n",
    "    return math.floor((train_set_split * dataset_size)/100)\n",
    "\n",
    "def create_train_and_validation_dirs(img_paths, train_set_size):\n",
    "    '''\n",
    "    Randomly select the desired number of images to be located in the new training directory. \n",
    "    The remaning images will be placed in a new directory to be used for validation.\n",
    "    '''\n",
    "    assert(len(img_paths) > 0)\n",
    "    assert(train_set_size > 0)\n",
    "    \n",
    "    # Randomly select images that will be in each set\n",
    "    random.shuffle(img_paths)\n",
    "    train_img_paths = img_paths[0:train_set_size]\n",
    "    validation_img_paths = img_paths[train_set_size:]\n",
    "\n",
    "    # Create training and validation directory \n",
    "    if not os.path.exists(training_dir):\n",
    "        os.makedirs(training_dir)\n",
    "    if not os.path.exists(validation_dir):\n",
    "        os.makedirs(validation_dir)\n",
    "        \n",
    "    # Place training and validation images in their respective directories\n",
    "    for x in train_img_paths:\n",
    "        os.rename(x, x.replace(original_data_dir, training_dir))\n",
    "    for x in validation_img_paths:\n",
    "        os.rename(x, x.replace(original_data_dir, validation_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and execute the helper methods defined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diegocasmo/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: \n",
      "        No images were found in the '../data/images_training_rev1' directory. Either training and validation\n",
      "        directories have already been created, or the datasets structure is not correctly setup.\n",
      "    \n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "img_paths = load_img_paths()\n",
    "if len(img_paths) > 0:\n",
    "    train_set_size = get_train_set_size(len(img_paths), 80)\n",
    "    create_train_and_validation_dirs(img_paths, train_set_size)\n",
    "else:\n",
    "    warning_msg = \"\"\"\n",
    "        No images were found in the '%s' directory. Either training and validation\n",
    "        directories have already been created, or the datasets structure is not correctly setup.\n",
    "    \"\"\" % original_data_dir\n",
    "    warnings.warn(warning_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
